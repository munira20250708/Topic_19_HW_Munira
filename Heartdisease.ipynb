{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20028914-722d-498e-8e7e-0772aeda0016",
   "metadata": {},
   "source": [
    "# Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39ffd38e-f8c9-4fa5-95f1-e581800098d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7168518d-9515-4038-9757-914d028a3341",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data\n",
    "df=pd.read_csv(\"heart.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4d47b2-da2a-49ab-8b4e-28293bcc06b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d09d54e-e1f2-4673-8c7d-7f2a0736b1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data column, type and null information, and missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c26b78-6167-4463-a753-ae6748bb670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b207c205-7f83-4f54-9ce1-6f777446ec55",
   "metadata": {},
   "source": [
    "As we can see on df.info() and df.isnull().sum() there is no missing value inside df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700be934-06d8-479c-b365-6e909e3c1a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the proportion of 0 and 1 in HeartDisease label\n",
    "df['HeartDisease'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb48863-4e15-49ed-ae9b-470834415564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(data = df, x='HeartDisease')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdffcd97-2b51-4211-8b1f-dbd077bcd1a2",
   "metadata": {},
   "source": [
    "- Most of the people in our data are infected.\n",
    "- Our target considered balanced target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9055ae86-4d58-43ef-9288-41235a4e1911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "#create teo different dataframe of majority and minority class \n",
    "df_majority = df[(df['HeartDisease']== 1)] \n",
    "df_minority = df[(df['HeartDisease']== 0)] \n",
    "\n",
    "# upsample minority class\n",
    "df_minority_upsampled = resample(df_minority,\n",
    "                          replace=True,      # sample with replacement\n",
    "                          n_samples=508,     # to match majority class\n",
    "                          random_state=27)   # reproducible results\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "df_upsampled = pd.concat([df_minority_upsampled, df_majority])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb84db3-c522-46ac-a657-0d9b105411eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check new class counts\n",
    "df_upsampled['HeartDisease'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d1fdc1-c55b-4f57-b90f-7c77ee7a3e8e",
   "metadata": {},
   "source": [
    "Our targets have been balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff7eb0-6a22-4bb0-9b5c-5c02921879a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataFrame that contains features that correlate closely with 'HeartDisease'\n",
    "#Correlatian Heatmap\n",
    "colormap = plt.cm.RdBu\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.title('SalePrice Correlation with 3 Features', y=1.05, size=15)\n",
    "sns.heatmap(df.corr(),linewidths=0.1,vmax=1.0, \n",
    "            square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e749bb4-0484-4dd6-b3c1-2bb49e2a6c9b",
   "metadata": {},
   "source": [
    "We can see in Correlation_Heatmap that the 'MaxHR' and 'Cholesterol' features do not have a close correlation because coefficients close to 0 or < 0 are meaningless, so we don't need to use them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c05bb4-4e0e-437a-a2a3-78f18bfc1454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To load a new DataFrame\n",
    "df = df[['Age', 'Sex', 'ChestPainType', 'RestingBP', 'FastingBS', 'RestingECG',\n",
    "         'Oldpeak', 'ST_Slope', 'HeartDisease']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def55815-e8dc-462c-a851-ab9ba6b60097",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f5f5a4-a82b-4ac6-908a-cbb12a6b319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot Encoding\n",
    "df = pd.get_dummies(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53087a4-59ec-4d76-962d-bf99191bbe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('heart_data_encoding.csv.gz', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c2dba2-02a1-4ecd-a5f1-b065ba0ce9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db172056-ebe0-41bd-b014-175a2cd1a99b",
   "metadata": {},
   "source": [
    "It can be seen in df.head() with the one hot encoding method can represent or make category type data as binary vectors with integer values, 0 and 1, where all elements will be worth 0 except for one element that is worth 1, that is, the element that has the value of that category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7695ed3f-364f-498b-805b-13e46b80ce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409e55e9-640e-42f3-bbb8-c946e41adb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining feature matrix(X) and response vector(y)\n",
    "X = df.loc[:, df.columns != 'HeartDisease']\n",
    "y = df['HeartDisease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb120d3-3843-4a6d-8294-830d9c633767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                    random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac9723f-90a7-4c64-a845-4235f8274b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Train two models with X_train and y_train (use Hyperparameter Tuning for random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff3aeec-a893-441d-89f1-529cc286dd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1ac0c2-879b-457a-b566-176d28612376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr = lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e281840-ca88-4014-940c-4f13fddf79f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier_rf = RandomForestClassifier(random_state=50, n_jobs=-1, max_depth=5,\n",
    "                                       n_estimators=100, oob_score=True)\n",
    "\n",
    "classifier_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6e8d37-1c27-4fe3-8a98-ce482227a88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameter Tuning for random forest\n",
    "\n",
    "rf = RandomForestClassifier(random_state=50, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be0c1b2-4601-433f-ad77-6afdf0fee1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create one variable (params) to deposit whatever we will try to do with the model\n",
    "params = {\n",
    "    'max_depth': [2,3,5,10,20],\n",
    "    'min_samples_leaf': [5,10,20,50,100,200],\n",
    "    'n_estimators': [10,25,30,50,100,200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c6aba5-188b-4024-a2b2-7b42bce6ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=rf,\n",
    "                           param_grid=params,\n",
    "                           cv = 5,\n",
    "                           n_jobs=-1, verbose=1, scoring=\"accuracy\")\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865e631e-9d47-461b-93b4-b64ead70a615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see best_score\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3473750-f65f-48b8-98a8-617c73baa9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see best_estimator (best_max_depth, best_min_samples_leaf)\n",
    "rf_best = grid_search.best_estimator_\n",
    "rf_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa00e22-38e3-4173-b432-12e80144cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "import joblib\n",
    "joblib.dump(lr, 'model_logisticregression.pkl')\n",
    "joblib.dump(classifier_rf, 'model_classifier_rf.pkl')\n",
    "joblib.dump(rf_best, 'model_classifier_rf_hypertuned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bf8408-497f-4fd6-a1f2-9b7dad134443",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluate the result with confusion matrix, classification report, and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6acce0-aa0c-45b6-ae02-915135d5edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For X_test predictions\n",
    "# Logistic Regression\n",
    "y_lr = lr.predict(X_test)\n",
    "\n",
    "# Random Forest Awal\n",
    "y_rf_before = classifier_rf.predict(X_test)\n",
    "\n",
    "# Random Forest dengan Hyperparameter Tuning\n",
    "y_rf_after = rf_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2768f6-7160-42ea-8464-0b88225329a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To display confusion_matrix results\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Logistic Regression : \\n\", confusion_matrix(y_test, y_lr))\n",
    "print(\"Random Forest Awal : \\n\", confusion_matrix(y_test, y_rf_before))\n",
    "print(\"Random Forest dengan Hyperparameter Tuning: \\n\", confusion_matrix(y_test, y_rf_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8744a3-6268-4dc2-b302-d6f23878a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluate the result with classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7180f6-388a-40fa-8cdb-6d34aa748536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Logistic Regression : \\n\\n\", classification_report(y_test, y_lr))\n",
    "print(\"Random Forest Awal : \\n\\n\", classification_report(y_test, y_rf_before))\n",
    "print(\"Random Forest dengan Hyperparameter Tuning: \\n\\n\", classification_report(y_test, y_rf_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d041d5-6180-4e5b-b564-3d1f76f055d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluate the result with AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c77a1ae-3f44-4d08-bd70-078122545669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_lr, pos_label=1) # pos_label: positive label\n",
    "print(\"Logistic Regression :\", auc(fpr, tpr))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_rf_before, pos_label=1) # pos_label: positive label\n",
    "print(\"Random Forest Awal :\", auc(fpr, tpr))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_rf_after, pos_label=1) # pos_label: positive label\n",
    "print(\"Random Forest dengan Hyperparameter Tuning:\", auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee05fa78-52be-431d-853c-ab04c98c612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Which model is better at predicting Heart Disease? Interpret the reason."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2034ef84-11ce-416f-b0c4-3456317845dd",
   "metadata": {},
   "source": [
    "A better model for predicting Heart Disease is 'Random Forest'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1656d192-63a1-44b3-b5ba-aeb06e9c95ad",
   "metadata": {},
   "source": [
    "Reason:\n",
    "After evalution to several models with 3 metrics (confusion matrix, classification report, and AUC), we can see that the prediction results with the 'Random Forest' model have the highest accuracy. In evaluating metrics with classification_report it can be seen that there are several combined metrics, to see how accurate our model is in predicting true positive and true negative heart disease (normal) then the matching metric is the 'recall' metric because the 'recall' metric shows the positive true rate of a model, the highest accuracy of the recall metric is in the prediction of the 'Random Forest' model of 86%. And in the evaluation with the AUC metric, it can be seen that the highest accuracy is in the prediction of the 'Random Forest' model of 85%, because the higher the AUC value, the better the model is in distinguishing between patients with heart disease and no heart disease (normal)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
